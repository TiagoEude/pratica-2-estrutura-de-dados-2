# -*- coding: utf-8 -*-
"""tweets-catcher.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dyRB4KpcQsvhE0rGe-9r9Zvhg5hEcN8G
"""

import os
import re
import tweepy as tw
import pandas as pd

with open('keys.txt', 'r') as file:
    consumer_key = file.readline().strip('\n')
    consumer_secret = file.readline().strip('\n')
    access_token = file.readline().strip('\n')
    access_token_secret = file.readline().strip('\n')

auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

api = tw.API(auth, wait_on_rate_limit=True)

public_tweets = api.home_timeline()

def deEmojify(text):
    regrex_pattern = re.compile(pattern = "["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags = re.UNICODE)
    return regrex_pattern.sub(r'',text)

query_search= "#flamengo -filter:retweets AND -filter:replies"
cursor_tweets = tw.Cursor(api.search, q=query_search, lang='pt').items(50)

lista = list()
for tweet in cursor_tweets:
  for palavra in tweet.text.split():
    if palavra.startswith("http") != True:
      palavra = deEmojify(palavra)
      palavra = palavra.lstrip('",.:?!@#$%&*()_-=+<>{}[]')
      palavra = palavra.rstrip('",.:?!@#$%&*()_-=+<>{}[]')
      lista.append(palavra)

for termo in lista:
  print(termo)

dfTweets = pd.DataFrame(lista)
dfTweets.to_csv("tweets.csv", index=False)
